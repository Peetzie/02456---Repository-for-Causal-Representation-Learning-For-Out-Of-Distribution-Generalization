{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16008\\1461185993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspines\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmspines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn import metrics\n",
    "\n",
    "from typing import *\n",
    "from IPython.display import Image, display, clear_output\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import math \n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus, relu\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Bernoulli, Normal\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotting import make_vae_plots\n",
    "\n",
    "CMNIST_list = torch.load(\"data/ColoredMNIST/train1.pt\")\n",
    "CMNIST = pd.DataFrame(CMNIST_list, columns = [\"image\", \"label\"])\n",
    "\n",
    "images = CMNIST.iloc[:,0]\n",
    "labels_df = CMNIST.iloc[:,1]\n",
    "labels = torch.tensor(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "transform_to_tensor = ToTensor()\n",
    "transform_to_tensor(images[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_CMNIST(image, label, environment):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.figure\n",
    "    plt.imshow(image)\n",
    "    plt.text(1,2,\"Label: {}\".format(label), backgroundcolor = \"white\",\n",
    "             color = \"black\", fontsize = 6)\n",
    "    plt.text(1,5,\"Environment: {}\".format(environment), backgroundcolor = \"white\",\n",
    "             color = \"black\", fontsize = 6)\n",
    "    plt.axis('off')\n",
    "    plt.show\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "show_CMNIST(images[0], labels[0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMNISTDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, pt_file, environment=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pt_file (string): Path to the pt file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            environment (integer): Integer indicating the environment the data comes from\n",
    "        \"\"\"\n",
    "        self.CMNIST_frame = pd.DataFrame(torch.load(pt_file))\n",
    "        self.transform = transform\n",
    "        self.environment = environment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.CMNIST_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.CMNIST_frame.iloc[idx, 0]\n",
    "        label = self.CMNIST_frame.iloc[idx, 1]\n",
    "        sample = {'image': image, 'label': label, \"environment\": self.environment}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = {'image': self.transform(image), 'label': label, \"environment\": self.environment}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnist_data = CMNISTDataset(pt_file = \"data/ColoredMNIST/train1.pt\", environment = 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(cmnist_data)):\n",
    "    sample = cmnist_data[i]\n",
    "\n",
    "    #print(i, sample['image'].shape, sample['label'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_CMNIST(**sample)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnist_data1 = CMNISTDataset(pt_file = \"data/ColoredMNIST/train1.pt\"\n",
    "                            , environment = 1\n",
    "                            , transform = transform_to_tensor)\n",
    "cmnist_data2 = CMNISTDataset(pt_file = \"data/ColoredMNIST/train2.pt\"\n",
    "                            , environment = 2\n",
    "                            , transform = transform_to_tensor)\n",
    "train_loader = DataLoader(ConcatDataset([cmnist_data1, cmnist_data2]), batch_size=256, num_workers=0, drop_last = True)\n",
    "\n",
    "cmnist_test_data = CMNISTDataset(pt_file = \"data/ColoredMNIST/test.pt\"\n",
    "                                 , environment = 3\n",
    "                                 , transform = transform_to_tensor)\n",
    "test_loader = DataLoader(cmnist_test_data, batch_size = 512, num_workers = 0, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(sample_batched):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, landmarks_batch = \\\n",
    "            sample_batched['image'], sample_batched['label']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['label'].size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        plt.figure()\n",
    "        show_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iVAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Bernoulli(logits=torch.zeros((1000,)))\n",
    "\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        eps = torch.empty_like(self.mu).normal_()\n",
    "        return self.mu + self.sigma * eps\n",
    "    # <- your code    \n",
    "        #return self.mu + self.sigma * self.sample_epsilon() # <- your code    \n",
    "    \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        return torch.normal(mean = self.mu, std = self.sigma)\n",
    "\n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        return - ((z - self.mu)**2)/(2*self.sigma**2) - torch.log(self.sigma) - math.log(math.sqrt(2 * math.pi)) # <- your code\n",
    "    \n",
    "    def mu(self):\n",
    "        return(self.mu, self.sigma)\n",
    "    #def log_prob(self, z:Tensor) -> Tensor:\n",
    "    #    \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "    #    dummy = self.rsample()\n",
    "    #    return self.z.log_prob(z) # <- your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a few CMNIST examples\n",
    "f, axarr = plt.subplots(4, 16, figsize=(16, 4))\n",
    "\n",
    "# Load a batch of images into memory\n",
    "sample = next(iter(train_loader))\n",
    "images = sample['image']\n",
    "label = sample['label']\n",
    "environment = sample['environment']\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(images[i].permute(1,2,0))\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.suptitle('MNIST handwritten digits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - NF-iVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iVariationalAutoencoder(nn.Module):\n",
    "    \"\"\"A Variational Autoencoder with\n",
    "    * a Bernoulli observation model `p_\\theta(x | z) = B(x | g_\\theta(z))`\n",
    "    * a Gaussian prior `p(z) = N(z | 0, I)`\n",
    "    * a Gaussian posterior `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int, device) -> None:\n",
    "        super(iVariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # define the parameters of the prior, chosen as p(z) = N(0, I)\n",
    "        ## setting the prior to a vector consisting of zeros with dimensions (1,2*latent_features)\n",
    "        # self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "        '''\n",
    "        According to page 31-32 the iVAE consist of 7 NNs:\n",
    "        1. lambdaf prior\n",
    "        \n",
    "        2. X-encoder (Classic image CNN)\n",
    "        3. (Y, E)-encoder\n",
    "        4. (X, Y, E)-merger/encoder\n",
    "\n",
    "        5. Decoder\n",
    "\n",
    "        1: Learn priors based on the label distribution for the given environment\n",
    "        2-4: Encoding X, encoding Y and E and merging these two encoders, to generate a \n",
    "             qz which is conditional on the environment.\n",
    "        5: Decodes the latent space through pz. Since the latent space now contain some measure\n",
    "           of environment, then this distribution pz is consequentially conditioned on the environment\n",
    "\n",
    "        NN 1-3 can be found in the variational inference funktion.\n",
    "        '''\n",
    "        #### PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS ####\n",
    "        #NN 1/5\n",
    "        self.Lambdaf_prior = nn.Sequential(\n",
    "            nn.Linear(in_features = 2, out_features=50), #Input\n",
    "            nn.Linear(in_features = 50, out_features=50), #Fully connected\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = 50, out_features = 20))  #Output\n",
    "        #### PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS PRIORS ####\n",
    "\n",
    "         #For NN 2/5 X-Encoder: Inference Network\n",
    "         #Encode the observation `x` into the parameters of the posterior distribution\n",
    "         #`q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x)), \\mu(x),\\log\\sigma(x) = h_\\phi(x)`\n",
    "        self.encoderCNN1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.encoderCNN2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.encoderCNN3 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        ##NN 3/5 (Y, E)-Encoder\n",
    "        self.YEencoder = nn.Sequential(\n",
    "            nn.Linear(in_features = 2, out_features=100),\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU())\n",
    "\n",
    "        ##NN 4/5 (X, Y, E)-merger/encoder\n",
    "        #remember to concatenate x.flatten, y, e before running this.\n",
    "        self.XYEmerger = nn.Sequential(\n",
    "            nn.Linear(in_features = 32 * 4 * 4 + 100, out_features=100),\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = 100, out_features = 2*latent_features))\n",
    "\n",
    "\n",
    "        #For NN 5/5 (Decoder): Generative Model\n",
    "        #Decode the latent sample `z` into the parameters of the observation model\n",
    "        #`p_\\theta(x | z) = \\prod_i B(x_i | g_\\theta(x))`\n",
    "        self.decoderFFN = nn.Linear(in_features=latent_features, out_features = 32 * 4 * 4)\n",
    "        self.decoderFFN2 = nn.Linear(in_features = 32 * 4 * 4, out_features = 32 * 4 * 4)\n",
    "        \n",
    "        self.decoderCNN1 = nn.ConvTranspose2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 2, padding = 1\n",
    "                              ,output_padding = 0)\n",
    "        self.decoderCNN2 = nn.ConvTranspose2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 2, padding = 1\n",
    "                              ,output_padding = 1)\n",
    "        self.decoderCNN3 = nn.ConvTranspose2d(in_channels = 32, out_channels = 3, kernel_size = 3, stride = 2, padding = 1\n",
    "                              ,output_padding = 1)\n",
    "\n",
    "    def prior_params(self, y, e):\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        ye = torch.cat((y, e), dim = 1)\n",
    "        ye = ye.to(torch.float32)\n",
    "        lambdaf_parameters = self.Lambdaf_prior(ye)\n",
    "\n",
    "        return lambdaf_parameters\n",
    "\n",
    "    #NN 4/7\n",
    "    def encoder(self, x, y, e):\n",
    "        x = self.relu(self.encoderCNN1(x))\n",
    "        x = self.relu(self.encoderCNN2(x))\n",
    "        x = self.relu(self.encoderCNN3(x))\n",
    "        x = x.view(x.size(0), -1) #NN 4/7\n",
    "\n",
    "        ye = torch.cat((y, e), dim = 1)\n",
    "        ye = ye.to(torch.float32)\n",
    "        ye = self.YEencoder(ye) #NN 5/7\n",
    "\n",
    "        xye = torch.cat((x,ye), dim = 1)\n",
    "        xye = self.XYEmerger(xye) #NN 6/7\n",
    "    \n",
    "        return xye\n",
    "   \n",
    "    #NN 7/7\n",
    "    def decoder(self, z):\n",
    "        \n",
    "        x = self.relu(self.decoderFFN(z))\n",
    "        x = self.relu(self.decoderFFN2(x))\n",
    "        \n",
    "        # reshape x and add CNN decoder\n",
    "        x = x.view(-1, 32, 4, 4)\n",
    "        \n",
    "        x = self.relu(self.decoderCNN1(x))\n",
    "        x = self.relu(self.decoderCNN2(x))\n",
    "        x = self.decoderCNN3(x)\n",
    "        return x    \n",
    "        \n",
    "    def posterior(self, x:Tensor, y:Tensor, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\"\"\"\n",
    "        \n",
    "        # compute the parameters of the posterior\n",
    "        h_x = self.encoder(x, y, z)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        \n",
    "        # return a distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def prior(self, y, e)-> Distribution:\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        #Expand prior_params til at være samme antal rækker som i den valgte batch size således at der fås\n",
    "        #en tensor med dimensionerne (batch_size, 2*latent_features), som så kan udfyldes med\n",
    "        prior_params = self.prior_params(y, e)\n",
    "        #chunk opdeler prior_params i to dele, de første 0-latent_features kollonner indeholder mu og \n",
    "        #de sidste n_latent_features inde holder sigmaerne. Nu er der to tensors, som begge har dim\n",
    "        #(batch_size, n_latent_features). Værdierne i disse tensors, kan bruges til at sample hvordan\n",
    "        #latent space ser ud (Den der hedder 'latent interpolations' i plots i bunden.)\n",
    "        mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "        \n",
    "        # return the distribution `p(z)`\n",
    "        #BEMÆRK at at det er log_sigma, dvs. at når den inputtes i ReparameterizedDiagonalGaussian så fås mu = 0, sigma = 1\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def observation_model(self, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "        px_means = self.decoder(z)\n",
    "        px_means = px_means.view(-1, *self.input_shape) # reshape the output #old\n",
    "        log_var = 0.01 * torch.ones(px_means.shape)\n",
    "        log_sigma = torch.log(torch.sqrt(log_var))\n",
    "        log_sigma = log_sigma.to(self.device)\n",
    "        #sandsynlighedsfordeling der giver 1 eller 0, baseret på log-odds givet i logits input fra p(x|z).\n",
    "        #Dvs. at px_logits angiver sandsynligheden for at det givne pixel er henholdsvist rød,grøn,blå. Pixel værdien\n",
    "        #er enten 0 eller 1. Når man sampler fra bernoulli fordelingen fås dermed et billede, som givet z, giver en figur,\n",
    "        #som er bestemt af de sandsynligheder der er i px_logits (p(x|z)). Dvs. at for et givet latents space, kan en\n",
    "        #figur/et tal reproduceres ud fra de beregnede sandsynligheder og den efterfølgende sample fra Bernoulli fordelingen.\n",
    "        return ReparameterizedDiagonalGaussian(mu = px_means, log_sigma = log_sigma)\n",
    "        \n",
    "\n",
    "    def forward(self, x, y, e) -> Dict[str, Any]:\n",
    "        \"\"\"compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)\"\"\"\n",
    "        \n",
    "        ###############################################################################################\n",
    "        # flatten the input\n",
    "        #x = x.view(x.size(0), -1) #outcommented as part of adding CNN\n",
    "        \n",
    "        #### Run through ENCODER and calculate mu and sigma for latent space sampling\n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.posterior(x, y, e)\n",
    "        \n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        #### LATENT SPACE\n",
    "        z = qz.rsample()\n",
    "        \n",
    "        #### DECODER\n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        ###############################################################################################\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        #(Indgår i beregning af kl-term (regularisering) ifm. ELBO) - og bruges også til interpolations visualisering\n",
    "        #til sidst.\n",
    "        pz = self.prior(y,e)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}\n",
    "    \n",
    "    \n",
    "    def sample_from_prior(self, y, e):\n",
    "        \"\"\"sample z~p(z) and return p(x|z)\"\"\"\n",
    "        \n",
    "        # Laver bare reconstruction baseret på latent space\n",
    "        #Kan evt. fjernes. Anvendes bare til at vise hvor god modellen er til at generere data baseret på\n",
    "        #latent space genererede data. Funktionen anvendes kun i make_vae_plots.\n",
    "        \n",
    "        # degine the prior p(z)\n",
    "        pz = self.prior(y, e)\n",
    "        \n",
    "        # sample the prior \n",
    "        z = pz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'z': z}\n",
    "    \n",
    "    def reduce(self, x:Tensor) -> Tensor:\n",
    "        \"\"\"for each datapoint: sum over all dimensions\"\"\"\n",
    "        return x.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "    def VariationalInference(self, x, y, e, beta):\n",
    "        self.beta = beta\n",
    "        # forward pass through the model\n",
    "        outputs = self.forward(x, y, e)\n",
    "        \n",
    "        # unpack outputs\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        # evaluate log probabilities\n",
    "        log_px = self.reduce(px.log_prob(x)) #log(p(x|z)): Sandsynligheden for at observere vores input variabel x\n",
    "        #givet vores latent space (tjekker modellens evne til at rekonstruere sig selv, ved at maximere sandsynlig-\n",
    "        #heden for at observere inputtet selv, givet det konstruerede latent space.\n",
    "        log_pz = self.reduce(pz.log_prob(z)) #log(p(z)): Sandsynligheden for at observere vores latent space, givet at\n",
    "        #latent space følger en standard-normal fordeling (Jo højere sandsynlighed jo bedre)\n",
    "        log_qz = self.reduce(qz.log_prob(z)) #log(q(z|x)): Sandsynligheden for at generere netop dette latent space givet \n",
    "        #vores input billede x. Denne værdi skal helst være lav?\n",
    "        \n",
    "        # compute the ELBO with and without the beta parameter: \n",
    "        # `L^\\beta = E_q [ log p(x|z) ] - \\beta * D_KL(q(z|x) | p(z))`\n",
    "        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`\n",
    "        #########################################################################################################\n",
    "        # Reconstruction loss: E_q [ log p(x|z) ]\n",
    "        # Regularization term: \\beta * D_KL(q(z|x) | p(z))` => Forsøger at tvinge fordelingen q(z|x) mod N(0,1)?\n",
    "        #########################################################################################################\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl\n",
    "        beta_elbo = log_px - self.beta * kl\n",
    "        \n",
    "        # loss\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # prepare the output\n",
    "        with torch.no_grad():\n",
    "            diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}\n",
    "            \n",
    "        return loss, diagnostics, outputs\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "latent_features = 10 #Husk at opdater denne parameter nede i 'initialization', hvis den skal bruges i VAE loopet også\n",
    "ivae = iVariationalAutoencoder(images[0].shape, latent_features, device)\n",
    "ivae = ivae.to(device)\n",
    "print(ivae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = next(iter(train_loader))\n",
    "images = sample['image']\n",
    "label = sample['label'].reshape(-1,1)\n",
    "environment = sample['environment'].reshape(-1,1)\n",
    "\n",
    "x = images\n",
    "y = label\n",
    "e = environment\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "e = e.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta = 1\n",
    "loss, diagnostics, outputs = ivae.VariationalInference(x, y, e, beta)\n",
    "print(f\"{'loss':6} | mean = {loss:10.3f}, shape: {list(loss.shape)}\")\n",
    "for key, tensor in diagnostics.items():\n",
    "    print(f\"{key:6} | mean = {tensor.mean():10.3f}, shape: {list(tensor.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "def show_CMNIST(image, label, environment, ax):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    ax.figure\n",
    "    ax.imshow(image.permute(1,2,0))\n",
    "    ax.text(1,2,\"Label: {}\".format(label), backgroundcolor = \"white\",\n",
    "             color = \"black\", fontsize = 8)\n",
    "    ax.text(1,5,\"Environment: {}\".format(environment), backgroundcolor = \"white\",\n",
    "             color = \"black\", fontsize = 8)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# VAE\n",
    "latent_features = 10 #Hyper parameter\n",
    "ivae = iVariationalAutoencoder(images[0].shape, latent_features, device)\n",
    "\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = torch.optim.Adam(ivae.parameters(), lr=1e-4) #Hyper parameter, tilføj evt. weight_decay (L2 regularization)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# num_epochs = 5 #hyper parametre\n",
    "# #batch size hyper parameter can be changed in the dataloader in the beginning.\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\">> Using device: {device}\")\n",
    "\n",
    "# # move the model to the device\n",
    "# ivae = ivae.to(device)\n",
    "# sample_counter = 0\n",
    "# # training..\n",
    "# while epoch < num_epochs:\n",
    "#     epoch+= 1\n",
    "#     training_epoch_data = defaultdict(list)\n",
    "#     ivae.train()\n",
    "    \n",
    "#     # Go through each batch in the training dataset using the loader\n",
    "#     # Note that y is not necessarily known as it is here\n",
    "#     for sample in train_loader: #tqdm\n",
    "#         sample_counter += 1\n",
    "        \n",
    "#         x = sample['image']\n",
    "#         x = x.to(device)\n",
    "\n",
    "#         y = sample['label'].reshape(-1,1)\n",
    "#         y = y.to(device)\n",
    "\n",
    "#         e = sample['environment'].reshape(-1,1)\n",
    "#         e = e.to(device)\n",
    "        \n",
    "#         # perform a forward pass through the model and compute the ELBO\n",
    "#         optimizer.zero_grad()\n",
    "#         loss, diagnostics, outputs = ivae.VariationalInference(x, y, e, beta)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # gather data for the current bach\n",
    "#         for k, v in diagnostics.items():\n",
    "#             training_epoch_data[k] += [v.mean().item()]\n",
    "            \n",
    "\n",
    "#     # gather data for the full epoch\n",
    "#     for k, v in training_epoch_data.items():\n",
    "#         training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "#     px = outputs['px']\n",
    "#     samples = px.sample()\n",
    "#     samples = samples.detach()\n",
    "\n",
    "#     xplot = x[0].cpu()\n",
    "#     samplesplot = samples[0].cpu()\n",
    "    \n",
    "#     fig, axes = plt.subplots(2,2)\n",
    "#     show_CMNIST(xplot, label=int(y[0]), environment=int(e[0]), ax = axes[0,0])\n",
    "#     show_CMNIST(samplesplot, label=int(y[0]), environment=int(e[0]),  ax = axes[0,1])\n",
    "#     axes[1,0].plot(training_data['elbo'], label = \"elbo\")\n",
    "#     display(fig)\n",
    "#     clear_output(wait = True)\n",
    "\n",
    "\n",
    "#     #if (epoch+1)%(num_epochs*0.1) == 0:\n",
    "#         #print(\"epoch: {}: training loss: elbo = {}, kl = {}, log_px = {}, total loss = {}\".format(epoch, training_data['elbo'][epoch-1], training_data['kl'][epoch-1], training_data['log_px'][epoch-1]), loss)\n",
    "    \n",
    "#     #Reproduce the figure from the begining of the notebook, plot the training curves and show latent samples\n",
    "#     #make_vae_plots(ivae, x, y, outputs, training_data, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ivae.state_dict(), '50epochs_iVAE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivae.load_state_dict(torch.load('50epochs_iVAE.pt', map_location=device))\n",
    "#ivae.load_state_dict(torch.load('50epochs_withchanges_and_detached_pz_ELBO.pt'))\n",
    "#Running model to test reconstruction on test data\n",
    "\n",
    "sample = next(iter(test_loader))\n",
    "x = sample['image']\n",
    "y = sample['label'].reshape(-1,1)\n",
    "e = sample['environment'].reshape(-1,1)\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "e = e.to(device)\n",
    "ivae = ivae.to(device)\n",
    "output = ivae.forward(x, y, e)\n",
    "\n",
    "px = output['px']\n",
    "samples = px.sample()\n",
    "\n",
    "fig, axes = plt.subplots(2,2)\n",
    "\n",
    "sample_id = 1\n",
    "\n",
    "x = x.to(torch.device(\"cpu\"))\n",
    "samples = samples.to(torch.device(\"cpu\")).detach()\n",
    "\n",
    "show_CMNIST(x[sample_id], label=int(y[sample_id]), environment=int(e[sample_id]), ax = axes[0,0])\n",
    "show_CMNIST(samples[sample_id], label=int(y[sample_id]), environment=int(e[sample_id]),  ax = axes[0,1])\n",
    "axes[1,0].plot(training_data['elbo'], label = \"elbo\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.clf()\n",
    "plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - PC algorithm based on latent variable\n",
    "\n",
    "(page 6-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy code for the testing of the PC algorithm to ensure the model data is prepared in the right format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cdt\n",
    "cdt.SETTINGS.rpath = 'C:/Program Files/R/R-4.2.2/bin/Rscript' # this path should point to your own R implementation !\n",
    "from cdt.causality.graph import PC\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "#names = np.array([\"A\",\"B\", \"C\", \"D\", \"E\"])\n",
    "#data_df = pd.DataFrame(data, columns = names)\n",
    "#pc_test = PC(CItest = 'gaussian', alpha = 0.05, verbose=False).create_graph_from_data(data_df[names[permutation]])\n",
    "\n",
    "#nx.draw(pc_test, with_labels=True, font_weight='bold')\n",
    "#plt.show()\n",
    "\n",
    "### Implementing PC algorithm on CMNIST iVAE result ###\n",
    "#load full CMNIST dataset --- determine causal latent variables based on training data\n",
    "# -> assume ALL test data are reserved to after all training is done.\n",
    "#cmnist_data1 = CMNISTDataset(pt_file = \"data/ColoredMNIST/train1.pt\"\n",
    "#                            , environment = 1\n",
    "#                            , transform = transform_to_tensor)\n",
    "#cmnist_data2 = CMNISTDataset(pt_file = \"data/ColoredMNIST/train2.pt\"\n",
    "#                            , environment = 2\n",
    "#                           , transform = transform_to_tensor)\n",
    "\n",
    "cmnist = ConcatDataset([cmnist_data1, cmnist_data2])\n",
    "loader = DataLoader(cmnist, batch_size = 40000, batch_sampler = None)\n",
    "\n",
    "sample = next(iter(loader))\n",
    "\n",
    "x = sample['image']\n",
    "y = sample['label'].reshape(-1,1)\n",
    "e = sample['environment'].reshape(-1,1)\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "e = e.to(device)\n",
    "\n",
    "ivae = ivae.to(device)\n",
    "\n",
    "output = ivae.forward(x, y, e)\n",
    "\n",
    "z = output['z']\n",
    "\n",
    "z_full = z\n",
    "x_full = x\n",
    "y_full = y\n",
    "e_full = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df = pd.DataFrame(z.detach())\n",
    "y_df = pd.DataFrame(y.detach())\n",
    "e_df = pd.DataFrame(e.detach())\n",
    "\n",
    "df = z_df; df['Y'] = y_df; df['E'] = e_df\n",
    "\n",
    "df.columns = ['Z1', 'Z2', 'Z3', 'Z4', 'Z5', 'Z6', 'Z7', 'Z8', 'Z9', 'Z10', 'Y', 'E']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing that the format of the df is as expected\n",
    "print(z[0])\n",
    "print(df.iloc[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PC(alpha=0.0000000001)\n",
    "pc_output = pc.predict(df)\n",
    "\n",
    "nx.draw(pc_output, with_labels=True, font_weight='bold', font_size = 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_output.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found indices:\n",
    "parents = torch.tensor([3,4,6,7])\n",
    "options = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "children = np.delete(options, parents)\n",
    "nParents = len(parents)\n",
    "nChildren = 10 - nParents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the lambda parameters in equation (12) on page 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 1\n",
    "lambda2 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Learning an invariant predictor (classifier, *w*) based on the causal latent variables\n",
    "\n",
    "(page 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFIER, *w*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#equation 12 p. 7 => Skal formodentligt bruges ifm. at køre data igennem test-sættet sådan at vi kan konvertere de kausale latente\n",
    "#variable fra træningssættet til test-sættet.\n",
    "#px = ivae.observation_model(z)\n",
    "#log_px_z = px.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy function from week 4:\n",
    "def accuracy(target, pred):\n",
    "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
    "\n",
    "#Building a classifier:\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Layers\n",
    "        self.input_layer = nn.Linear(in_features=4, out_features = 50)\n",
    "        self.layer1 = nn.Linear(in_features = 50, out_features = 100)\n",
    "        self.output_layer = nn.Linear(in_features = 100, out_features = 1)\n",
    "\n",
    "        #activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    #forward function(self, x):\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.sigmoid(self.output_layer(x))\n",
    "\n",
    "        return x\n",
    "    # \n",
    "\n",
    "classifier = Classifier()\n",
    "classifier.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "\n",
    "#Define loss function\n",
    "loss_fn = nn.BCELoss() \n",
    "#The adam algorithm automatically use momentum\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = 1e-4) \n",
    "\n",
    "#Test model\n",
    "z = output['z']\n",
    "z = torch.index_select(z, 1, parents)\n",
    "out = classifier(z[1])\n",
    "print(\"Output shape:\", out.size())\n",
    "print(f\"Output logits:\\n{out.detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set iVAE to eval - the no.grad thing is not an issue as we are only using the encoder.\n",
    "ivae.eval()\n",
    "\n",
    "#TRAINING THE CLASSIFIER\n",
    "epoch = 0\n",
    "num_epochs = 25 #hyper parametre\n",
    "#batch size hyper parameter can be changed in the dataloader in the beginning.\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# training..\n",
    "training_epoch_data = []\n",
    "test_epoch_data = []\n",
    "test_acc, train_acc = [], []\n",
    "\n",
    "while epoch < num_epochs:\n",
    "    epoch+= 1\n",
    "    training_batch_data = []\n",
    "    test_batch_data = []\n",
    "    classifier.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    for sample in train_loader:\n",
    "        x = sample['image']\n",
    "        x = x.to(device)\n",
    "\n",
    "        y = sample['label'].to(torch.float32)\n",
    "        y = y.to(device)\n",
    "\n",
    "        e = sample['environment'].to(torch.float32)\n",
    "        e = e.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBO\n",
    "        qz = ivae.posterior(x, y.reshape(-1,1), e.reshape(-1,1))\n",
    "        z = qz.rsample()\n",
    "        z = torch.index_select(z, 1, parents)\n",
    "\n",
    "        #Get classification prediction\n",
    "        output = classifier(z).view(-1)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gather data for the current batch\n",
    "        training_batch_data.append(loss)\n",
    "            \n",
    "\n",
    "    # gather data for the full epoch\n",
    "    training_epoch_data.append(torch.tensor(training_batch_data).mean())\n",
    "\n",
    "    print(\"Epoch {} : , Loss {}\".format(epoch, training_epoch_data[epoch-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_full = DataLoader(cmnist_test_data, batch_size = 20000, batch_sampler = None)\n",
    "\n",
    "sample = next(iter(test_data_full))\n",
    "\n",
    "x_test = sample['image']\n",
    "y_test = sample['label'].reshape(-1,1)\n",
    "e_test = sample['environment'].reshape(-1,1)\n",
    "\n",
    "ivae = ivae.to(device)\n",
    "output = ivae.forward(x_test, y_test, e_test)\n",
    "\n",
    "z_test = output['z']\n",
    "\n",
    "z_full = z_test.detach()\n",
    "x_full = x_test.detach()\n",
    "y_full = y_test.detach()\n",
    "e_full = e_test.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zp = torch.randn(z_full.shape[0], nParents)\n",
    "Zc = torch.randn(z_full.shape[0], nChildren)\n",
    "Z = torch.randn(z_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "Zp = Zp.to(device)\n",
    "Zc = Zc.to(device)\n",
    "Z = Z.to(device)\n",
    "\n",
    "ivae = ivae.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([Zp, Zc], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eq. 12 and classification based on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_BCE = nn.BCELoss()\n",
    "\n",
    "Zp.requires_grad = True\n",
    "Zc.requires_grad = True\n",
    "\n",
    "\n",
    "optimizerBCE = optim.Adam(params=[Zp, Zc], lr=1e-4)\n",
    "\n",
    "\n",
    "def get_reconstruction(Zp, Zc):\n",
    "    \n",
    "\n",
    "    Z[:,parents] = Zp\n",
    "    Z[:,children] = Zc\n",
    "    \n",
    "    return(ivae.observation_model(Z))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    sample = next(iter(test_data_full))\n",
    "    x = sample['image']\n",
    "    x = x.to(device)\n",
    "\n",
    "\n",
    "    px = get_reconstruction(Zp,Zc)\n",
    "    reconstructions = px.sample()\n",
    "    reconstructions = torch.sigmoid(reconstructions)\n",
    "    \n",
    "    BCE = torch.nn.functional.binary_cross_entropy(reconstructions, x, reduction = 'none')\n",
    "    #print(BCE.mean(1))\n",
    "    loss = BCE.mean(1)\n",
    "    print(loss.mean())\n",
    "    loss = loss.mean()\n",
    "    optimizerBCE.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizerBCE.step()\n",
    "    print(Z[0,:])\n",
    "    print(\"Step done\")\n",
    "    \n",
    "\n",
    "pred_y = classifier(Zp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(device)\n",
    "pred_y = classifier(Zp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnist = ConcatDataset([cmnist_data1, cmnist_data2])\n",
    "loader = DataLoader(cmnist, batch_size = 40000, batch_sampler = None)\n",
    "\n",
    "sample = next(iter(loader))\n",
    "\n",
    "x = sample['image']\n",
    "y = sample['label'].reshape(-1,1)\n",
    "e = sample['environment'].reshape(-1,1)\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "e = e.to(device)\n",
    "\n",
    "#ivae = ivae.cpu()\n",
    "output = ivae.forward(x, y, e)\n",
    "\n",
    "z = output['z']\n",
    "\n",
    "z_full = z.detach()\n",
    "x_full = x.detach()\n",
    "y_full = y.detach()\n",
    "e_full = e.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(z_test[:,range(0,4)], dim = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = ivae.observation_model(z_full)\n",
    "log_px = px.log_prob(x_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parents = len(parents)\n",
    "options = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "ivae.eval()\n",
    "\n",
    "nll = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0,10):\n",
    "        px = ivae.observation_model(z_full)\n",
    "        \n",
    "        nll_temp = -(px.log_prob(x_full).sum() + lambda1*torch.norm(z_full[:,i]).sum() + lambda2*torch.norm(z_full[:,children].sum()))\n",
    "        nll.append(nll_temp)\n",
    "        print(\"done i = {}\".format(i))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(nll)\n",
    "plt.plot(nll)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3 (v3.8.3:6f8c8320e9, May 13 2020, 16:29:34) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
